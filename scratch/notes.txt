
# Run m-slam all the way through to splatting
# Starting with the soneva reef dataset one, left hand side (LHS) only first.

# First had to downsample to 1600. Used:
/home/bwilliams/encode/code/scratch/downsample_img.sh # change dirs in the script for future use

# Then have to convert to png:
conda activate mast3r-slam
python /home/bwilliams/encode/code/scratch/jpeg2png.py # again, change dirs as appropriate

# Now try mast3r-slam:
python main.py --dataset datasets/reef_soneva --config config/base.yaml

# Some notes:
- It seems to sort of work. There are some gaps and I wonder if these are because its only using mono not stereo?
  so how to add in second camera?
- Will try to make splat from it, but also don't have the groundtruth from agisoft to compare against like we did
  with the small patch from sweet-coral

# Next I solved the intrinsics estimation. More notes in Notion, but in short we run colmap on the first 100 raw
# images (not keyframes) which can be used to estimate the intrinsics with a bash script that calls colmap functions.
# This will also output a summary text file on how well it did:
bash /home/bwilliams/encode/code/scratch/estimate_intrinsics.sh \
--images_path /home/bwilliams/encode/data/soneva/ootbm/LHS_downsampled_png/ \
--dataset_name reef_soneva

# Then we take the outputs and create an intrinsics.yaml that can be used by master-slam to improve the slam. 
# It also will convert the intrinsics to a cameras.bin file,  which is used by lichtfeld-studio for splatting,
# and will put this inside the for_splat folder inside the intermediate_data directory.
conda activate mast3r-slam
python /home/bwilliams/encode/code/scratch/shuttle_intrinsics.py --dataset reef_soneva

# Next, we can actually run m-slam. We will find the reconstruction is better with these intrinisics than with
# the default intrinsics yaml used by m-slam:
cd /home/bwilliams/encode/code/MASt3R-SLAM
python /home/bwilliams/encode/code/MASt3R-SLAM/main.py \
 --dataset /home/bwilliams/encode/data/soneva/ootbm/LHS_downsampled_png \
 --config /home/bwilliams/encode/code/MASt3R-SLAM/config/base.yaml \
 --calib /home/bwilliams/encode/data/intermediate_data/reef_soneva/intrinsics.yaml

 # Getting a strange `FileNotFoundError: [Errno 2] No such file or directory` error? For some reason
 # it seems trying to run on reef data as the first dataset after reboot doesn't work. So first run the 
 # demo data, then try the above command to run the reef data again.

# Now master-slam has run we want to convert the poses estimated by m-slam to the colmap format.
# We'll put this converted file into the splatting folder and copy over the keyframes from m-slam as well
python /home/bwilliams/encode/code/scratch/cam_pose_keyframes_shuttle.py --dataset reef_soneva

# Optional, could try add some funcionality to make points3D.bin, potentially from the points3D.bin output
# by master-slam? Apparently its not needed as lichtfeld-studio doesn't need it, its just speeds up/improves
# the early stages of splatting?

# Now lets try splatting with the m-slam outputs and conversions to colmap:
cd /home/bwilliams/encode/code/lichtfeld-studio
/home/bwilliams/encode/code/lichtfeld-studio/build/LichtFeld-Studio \
 -d /home/bwilliams/encode/data/intermediate_data/reef_soneva/for_splat \
 -o /home/bwilliams/encode/code/lichtfeld-studio/output/m-slam_reef_soneva \
 --headless \
 --gut \
 -i 10000



