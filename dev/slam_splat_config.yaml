# Pipeline Configuration Template
# Copy this file and customize for each run

# Unique identifier for this run (used for output directory naming)
run_name: "pipeline_test3"

# Pipeline Control
pipeline:
  # Which environment/conda activation to use
  # "ben-splat-env" for COLMAP steps, "mast3r-slam" for MASt3R steps
  python_env_colmap: "ben-splat-env"  # For steps 1, 2
  python_env_mslam: "mast3r-slam"     # For steps 3, 4, 5
  # Enable step-by-step confirmation (useful for debugging)
  interactive: false
  # Skip completed steps if outputs exist
  skip_existing: true

# Paths 
paths:
  # Raw input images (must be PNG)
  images_path: "/home/bwilliams/encode/data/soneva/ootbm/LHS_downsampled_png/"
  # Sirectory where intermediate data and outputs will be stored
  intermediate_data_root: "/home/bwilliams/encode/data/intermediate_data"
  # MASt3R-SLAM installation directory
  mast3r_slam_root: "/home/bwilliams/encode/code/MASt3R-SLAM"
  # LichtFeld-Studio binary path
  lichtfeld_binary: "/home/bwilliams/encode/code/lichtfeld-studio/build/LichtFeld-Studio"

# Step 1: COLMAP Intrinsics Estimation (estimate_intrinsics.py)
#TODO: see TODO in pipeline.py about how 100 images might be overkill.
intrinsics_estimation:
  # Number of images to use for calibration
  num_images: 100
  # Camera model: "OPENCV" (GoPro/wide-angle) or "OPENCV_FISHEYE" (extreme fisheye)
  # TODO: should be able to take any standard colmap camera model
  camera_model: "OPENCV"
  # Overwrite existing output without prompting
  overwrite: true

# Step 2: Intrinsics Conversion (shuttle_intrinsics.py)
intrinsics_conversion:
  # Also save original camera model as cameras_{MODEL}.bin/txt
  keep_original: false

# Step 3: MASt3R-SLAM
mast3r_slam:
  # Config file (relative to mast3r_slam_root or absolute path)
  config: "config/base.yaml"
  # Enable visualization (requires manual Ctrl+C to continue pipeline after SLAM completes)
  # Set to false for automated runs. TODO: Run visualization in separate process to avoid blocking.
  enable_visualization: false
  # Additional arguments to pass to MASt3R-SLAM (optional)
  # Example: ["--single_thread"]
  extra_args: []

# Step 4: Pose/Keyframe Conversion (cam_pose_keyframes_shuttle.py)
pose_conversion:
  # Use symlinks instead of copying images (faster, saves space)
  link_images: false
  # Camera ID (null for auto-detect from cameras.txt)
  camera_id: null

# Step 5: PLY to COLMAP points3D (mslam_ply_to_points3d.py)
ply_conversion:
  # Percentage of points to sample (10% = ~500K-1M points)
  # Lower = faster, less memory. Higher = more detail
  sample_percentage: 10.0

# Step 6: Gaussian Splatting Training (train_splat.py)
gaussian_splatting:
  # Run in headless mode (no GUI)
  headless: true
  # Number of training iterations
  iterations: 25000
  # Maximum splat count after densification
  max_cap: 1000000
  # Additional LichtFeld-Studio arguments
  # Example: ["--random", "--save-every", "10000"]
  extra_args: []

